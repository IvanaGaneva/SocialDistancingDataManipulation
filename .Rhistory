DAILY_DATA$Day_of_Week <- ordered(DAILY_DATA$Day_of_Week,
levels=c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday"))
by_day <- DAILY_DATA  %>%
select(Day_of_Week, Sales) %>% na.omit() %>%
group_by(Day_of_Week) %>%
summarise(mean = mean(Sales))
ggplot(by_day, aes(x=Day_of_Week, y = log(mean))) +
geom_bar(stat="identity", fill = 'darkblue') +
xlab('Weekday') +
ylab('Log(Average Daily Sales)') +
ggtitle('Log-Scaled Average Value of Daily Sales per Weekday') +
theme_bw() +
theme(panel.border = element_blank()) +
theme(plot.title = element_text(color = "#4c5666", face = "bold", size = 14, hjust = 0.5)) +
theme(axis.text.x = element_text(size = 12),
axis.text.y = element_text(size = 12),
axis.title.x = element_text(size = 12),
axis.title.y = element_text(size = 12))
# 2.3. Exploring Weekly Patterns
DAILY_DATA <- DAILY_DATA %>% mutate(Month = as.factor(format(Date, '%b')))
DAILY_DATA$Month <- ordered(DAILY_DATA$Month,
levels = c("Jan", "Feb", "Mar", 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'))
by_mon <- DAILY_DATA %>%
select(Month, Sales) %>% na.omit() %>%
group_by(Month) %>% summarise(mean = mean(Sales))
ggplot(by_mon, aes(x = Month, y = mean)) +
geom_bar(stat="identity", fill = 'darkblue') +
xlab('Month') +
ylab('Average Daily Sales') +
ggtitle('Average Value of Daily Sales per Month') +
theme_bw() +
theme(panel.border = element_blank()) +
theme(plot.title = element_text(color = "#4c5666", face = "bold", size = 14, hjust = 0.5)) +
theme(axis.text.x = element_text(size = 12),
axis.text.y = element_text(size = 12),
axis.title.x = element_text(size = 12),
axis.title.y = element_text(size = 12))
# 4.1. Benchmarks.
naive_mnthly <- naive(window(mnthly, start = c(2015, 1), end = c(2017, 10)), h = 4)
summary(naive_mnthly)
autoplot(naive_mnthly)
checkresiduals(naive_mnthly)
snaive_mnthly <- snaive(window(mnthly, start = c(2015, 1), end = c(2017, 10)), h = 4)
summary(snaive_mnthly)
autoplot(snaive_mnthly)
checkresiduals(snaive_mnthly)
# Performs better in terms of RMSE than the regular naive monthly model, despite the
# rejected seasonality. Leads to the idea of incorporating dummy variables for the months.
mnthly_aa <- auto.arima(mnthly)
summary(mnthly_aa)
# autoplot(mnthly_aa)
# inside the unit circle - inverse MA root
checkresiduals(mnthly_aa)
# apart from the 4th lag, looks (mostly) normally distributed
fc_opsa <- forecast(mnthly_aa, h = 4)
autoplot(mnthly_aa)
# 4.2. Model I - 'Improved' Benchmark
# Holt-Winters HW approach for smoothing:
fc1 <- hw(window(mnthly, start = c(2015, 1), end = c(2017, 10)), seasonal = 'multiplicative',
h = 4)
summary(fc1)
autoplot(fc1) + autolayer(fitted(fc1))
# Exponential Smoothing:
mnthly %>% window(start = c(2015, 1), end = c(2017, 10)) %>%
ets() %>%
forecast() %>%
autoplot()
# 4.3. Main model
DAILY_DATA <- DAILY_DATA %>% mutate(Actual_Monthly = 0, LO = 0)
for(i in 1:nrow(DAILY_DATA)){
for(j in levels(factor(DAILY_DATA$Year_Month))){
if(DAILY_DATA$Year_Month[i] == j) {
DAILY_DATA$Actual_Monthly[i] <- filter(MONTHLY_DATA, Year_Month == j)$Actual
DAILY_DATA$LO[i] <- filter(MONTHLY_DATA, factor(Year_Month) == j)$LO
}
}
}
DAILY_DATA <- DAILY_DATA %>%
dummy_cols(select_columns = 'Day_of_Week', remove_first_dummy = T,
remove_selected_columns = T)
df_for_carimax <- DAILY_DATA %>%
select(-c("Date","Year_Month","Sales", "num_workdays", "Month")) %>%
mutate(Mon_fin = `#Mon`*Mon_avg,
Tue_fin = `#Tue`*Tue_avg,
Wed_fin = `#Wed`*Wed_avg,
Thu_fin = `#Thu`*Thu_avg,
Fri_fin = `#Fri`*Fri_avg) %>%
select(-c(`#Mon`, `#Tue`, `#Wed`, `#Thu`, `#Fri`, "Mon_avg", "Tue_avg", "Wed_avg",
"Thu_avg", "Fri_avg"))
lm_mod <- lm(Actual_Monthly ~., data = df_for_carimax[1:729,])
summary(lm_mod)
forecast <- rep(NA, nrow(df_for_carimax))
lwr <- rep(NA, nrow(df_for_carimax))
upr <- rep(NA, nrow(df_for_carimax))
wish_to_predict <- c(740:745, 760:765, 779:787, 802:808)
for(i in wish_to_predict){
lm_mod <- lm(Actual_Monthly ~., data = df_for_carimax[1:(i-1),],
na.action = na.exclude)
fcst <- predict(lm_mod, newdata = df_for_carimax[i,], interval = 'confidence',
level = 0.95, na.action = na.pass)
forecast[i] <- fcst[1]
lwr[i] <- fcst[2]
upr[i] <- fcst[3]
}
df_forecasts <- data.frame(fc = forecast, lwr = lwr, upr = upr)
OPSA <- cbind(DAILY_DATA, df_forecasts)
View(OPSA)
select(OPSA, c('Date', 'Actual_Monthly', 'fc', 'lwr', 'upr'))
OPSA <- select(OPSA, c('Date', 'Actual_Monthly', 'fc', 'lwr', 'upr'))
head(OPSA)
str(OPSA)
ggplot(OPSA, aes(x = Date, y = Actual_Monthly)) +
geom_line(color = 'darkblue', size = 1) +
geom_linne(aes(x = Date, y = fc), color = '#ba220b') +
scale_y_continuous(breaks = seq(15000, 350000, by = 50000)) +
scale_x_date(date_breaks = '1 month', date_labels = "%b, %Y") +
xlab('') +
ylab('Monthly Actual Sales') +
theme_bw() +
ggtitle('Monthly Actual Sales Reported, \nCountry 1, Brand A') +
theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1, size = 12),
axis.title.y = element_text(size = 12),
panel.border = element_blank(),
plot.title = element_text(color = "#4c5666", face = "bold", size = 14, hjust = 0))
ggplot(OPSA, aes(x = Date, y = Actual_Monthly)) +
geom_line(color = 'darkblue', size = 1) +
geom_line(aes(x = Date, y = fc), color = '#ba220b') +
scale_y_continuous(breaks = seq(15000, 350000, by = 50000)) +
scale_x_date(date_breaks = '1 month', date_labels = "%b, %Y") +
xlab('') +
ylab('Monthly Actual Sales') +
theme_bw() +
ggtitle('Monthly Actual Sales Reported, \nCountry 1, Brand A') +
theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1, size = 12),
axis.title.y = element_text(size = 12),
panel.border = element_blank(),
plot.title = element_text(color = "#4c5666", face = "bold", size = 14, hjust = 0))
library(ggplot2)
library(ReadAxfBOM) # load library for axf data
install.packages('ReadAxfBOM')
library(ReadAxfBOM) # load library for axf data
library(foreign)
dataset = read.spss("C:/Users/Ivana/Downloads/Microsoft.SkypeApp_kzf8qxf38zg5c!App/All/Employees.sav",
to.data.frame=TRUE)
View(dataset)
dataset = read.spss("C:/Users/Ivana/Downloads/Microsoft.SkypeApp_kzf8qxf38zg5c!App/All/Employees.sav",
to.data.frame=TRUE,
reencode = T)
View(dataset)
View(dataset)
dataset = read.spss("C:/Users/Ivana/Downloads/Microsoft.SkypeApp_kzf8qxf38zg5c!App/All/Employers.sav",
to.data.frame=TRUE,
reencode = T)
View(dataset)
View(dataset)
opa <- read.dta('D:/2019-04-16/docs/IDEA/YEAR 2/APE/dataHW1.1.dta')
library(foreign)
opa <- read.dta('D:/2019-04-16/docs/IDEA/YEAR 2/APE/dataHW1.1.dta')
library(haven)
opa <- read_dta('D:/2019-04-16/docs/IDEA/YEAR 2/APE/dataHW1.1.dta')
View(opa)
library(ggplot2)
ggplot(opa, aes(x = rgdpl, y = xropen)) + geom_point
ggplot(opa, aes(x = rgdpl, y = xropen)) + geom_point()
nrow(opa[opa$xropen < 0,])
table(xropen)
table(opa$xropen)
161+125+93
379/13141
ggplot(opa, aes(x = rgdpl, y = xropen)) + geom_point() + geom_smooth()
ggplot(opa, aes(x = xropen, y = rgdpl)) + geom_point() + geom_smooth()
ggplot(opa, aes(x = xropen, y = rgdpl)) + geom_point() + geom_smooth()
ggplot(opa[opa$xropen >= 0,], aes(x = xropen, y = rgdpl)) + geom_point() + geom_smooth()
#### Analytical Solution
It is clear that we can reduce the number of constraints by substituting the second and third binding constraints into the first one.
From this, one can proceed as usual to combine the respective F.O.C.s for $c_t$ and $c_{t+1}$ together with the expression above for $k_{t+1}$ to obtain the inter-temporal Euler equation for consumption.
Once the steady-state is imposed on $k$, i.e. once we look for $k_{ss}$ such that $k_{t+1} = k_t = k_{ss}$ for all $t$, we have that:
(1/(4^0.33*0.31^0.67))^(1/0.67)
(1-0.0625-0.33*(1.629676*0.31)^0.67*4^(-0.67))^(-1)
(1-0.0625-0.33*(1.629676*0.31)^(0.67)*4^(-0.67))^(-1)
1-0.0625
0.33*(1.629676*0.31)^(0.67)*4^(-0.67)
0.9375-0.0825
1/0.855
(1.629676*0.31)
(1.629676*0.31)/4
0.1262999^0.67
0.1262999^(0.67)
0.33*0.25
1-0.0625-0.0825
1/0.855
library(pracma)
install.packages('pracm')
install.packages('pracma')
library(pracma)
c <- c(1,2,3)
c[1]
c(1)
st_state_function <- function(h, theta, z, k_to_y = 4, i_to_y = 0.25){
# The Five Constraints:
#   (which will be equated to zero when obtaining the roots/solution)
# - The Capital-Output Ratio:
k_to_y_constr = k_to_y - x[1]/x[3]
# - The Investment-Output Ratio:
i_to_y_constr = i_to_y - x[4]*x[2]/x[3]
# - The Euler Equation:
ee_constr = (1 - x[4] - (1-theta)*((z*h)/x[2])^theta)*x[5]
# - The Budget/Resource Constraint:
b_constr = x[3] - x[1] - x[2]*x[4]
# - Cobb-Douglas Production:
cd_prod_constr = x[3] - x[2]^(1-theta)*((z*h)^(theta))
# For the five variables of: c_ss, k_ss, y_ss, delta, and beta
# - these are five and not six since we can isolate i_ss as i_ss = k_ss*delta
#   in the budget constraint
# - also considering z to be a parameter rather than a variable
#   [following the arguments in the analytical part - it cancels out]
# - having put these variables into a vector x to match the syntax of the fsolve funct:
# x = (c_ss, k_ss, y_ss, delta, beta)
#     x[1]   x[2]  x[3]  x[4]   x[5]
return(c(k_to_y_constr, i_to_y_constr, ee_constr, b_constr, cd_prod_constr))
}
# STEP 2:
# Setting the initial guess:
x_0 <- c(0.7, 3.5, 1, 0.1, 1)
# STEP 3:
# Solving the function, i.e. finding the steady state numerically:
x_ss <- fsolve(st_state_function(z = 2), x0 = x_0)
x_0[1]
st_state_function <- function(x, h = 0.31, theta = 0.67, z, k_to_y = 4, i_to_y = 0.25){
# The Five Constraints:
#   (which will be equated to zero when obtaining the roots/solution)
# - The Capital-Output Ratio:
k_to_y_constr = k_to_y - x[1]/x[3]
# - The Investment-Output Ratio:
i_to_y_constr = i_to_y - x[4]*x[2]/x[3]
# - The Euler Equation:
ee_constr = (1 - x[4] - (1-theta)*((z*h)/x[2])^theta)*x[5]
# - The Budget/Resource Constraint:
b_constr = x[3] - x[1] - x[2]*x[4]
# - Cobb-Douglas Production:
cd_prod_constr = x[3] - x[2]^(1-theta)*((z*h)^(theta))
# For the five variables of: c_ss, k_ss, y_ss, delta, and beta
# - these are five and not six since we can isolate i_ss as i_ss = k_ss*delta
#   in the budget constraint
# - also considering z to be a parameter rather than a variable
#   [following the arguments in the analytical part - it cancels out]
# - having put these variables into a vector x to match the syntax of the fsolve funct:
# x = (c_ss, k_ss, y_ss, delta, beta)
#     x[1]   x[2]  x[3]  x[4]   x[5]
return(c(k_to_y_constr, i_to_y_constr, ee_constr, b_constr, cd_prod_constr))
}
# STEP 3:
# Solving the function, i.e. finding the steady state numerically:
x_ss <- fsolve(st_state_function(z = 2), x0 = x_0)
h = 0.31; theta = 0.67; k_to_y = 4; i_to_y = 0.25;
z = 2; # as suggested
st_state_function <- function(x){
# The Five Constraints:
#   (which will be equated to zero when obtaining the roots/solution)
# - The Capital-Output Ratio:
k_to_y_constr = k_to_y - x[1]/x[3]
# - The Investment-Output Ratio:
i_to_y_constr = i_to_y - x[4]*x[2]/x[3]
# - The Euler Equation:
ee_constr = (1 - x[4] - (1-theta)*((z*h)/x[2])^theta)*x[5]
# - The Budget/Resource Constraint:
b_constr = x[3] - x[1] - x[2]*x[4]
# - Cobb-Douglas Production:
cd_prod_constr = x[3] - x[2]^(1-theta)*((z*h)^(theta))
# For the five variables of: c_ss, k_ss, y_ss, delta, and beta
# - these are five and not six since we can isolate i_ss as i_ss = k_ss*delta
#   in the budget constraint
# - also considering z to be a parameter rather than a variable
#   [following the arguments in the analytical part - it cancels out]
# - having put these variables into a vector x to match the syntax of the fsolve funct:
# x = (c_ss, k_ss, y_ss, delta, beta)
#     x[1]   x[2]  x[3]  x[4]   x[5]
return(c(k_to_y_constr, i_to_y_constr, ee_constr, b_constr, cd_prod_constr))
}
# STEP 2:
# Setting the initial guess:
x_0 <- c(0.7, 3.5, 1, 0.1, 1)
# STEP 3:
# Solving the function, i.e. finding the steady state numerically:
x_ss <- fsolve(st_state_function(z = 2), x0 = x_0)
# STEP 3:
# Solving the function, i.e. finding the steady state numerically:
x_ss <- fsolve(st_state_function, x0 = x_0)
# STEP 3:
# Solving the function, i.e. finding the steady state numerically:
x_ss <- fsolve(st_state_function, x0 = x_0)
fsolve(st_state_function, x0 = x_0)
# STEP 3:
# Solving the function, i.e. finding the steady state numerically:
x_ss <- fsolve(st_state_function, x0 = x_0, .Machine$double.eps^(0.5))
# STEP 3:
# Solving the function, i.e. finding the steady state numerically:
x_ss <- fsolve(st_state_function, x0 = x_0, tol = .Machine$double.eps^(0.5))
library('nleqslv')
install.packages('nleqslv')
library('nleqslv')
# STEP 3:
# Solving the function, i.e. finding the steady state numerically:
x_ss <- nleqslv(st_state_function, x0 = x_0)
# STEP 3:
# Solving the function, i.e. finding the steady state numerically:
x_ss <- nleqslv(st_state_function, x = x_0)
View(x_ss)
# STEP 3:
# Solving the function, i.e. finding the steady state numerically:
x_ss <- nleqslv(st_state_function, x = x_0, method = 'Newton')
View(x_ss)
x_ss['message']
# STEP 3:
# Solving the function, i.e. finding the steady state numerically:
x_ss <- nleqslv(st_state_function, x = x_0, method = 'Newton', control = 'allowSingular')
# STEP 3:
# Solving the function, i.e. finding the steady state numerically:
x_ss <- nleqslv(st_state_function, x = x_0, method = 'Newton',
control = list(allowSingular = T))
View(x_ss)
# STEP 2:
# Setting the initial guess:
x_0 <- c(0.7, 3.9, 1, 0.07, 1)
# STEP 3:
# Solving the function, i.e. finding the steady state numerically:
x_ss <- nleqslv(st_state_function, x = x_0, method = 'Newton',
control = list(allowSingular = T))
View(x_ss)
# STEP 2:
# Setting the initial guess:
x_0 <- c(0.7, 3.9, 1, 0.07, 0.9)
# STEP 3:
# Solving the function, i.e. finding the steady state numerically:
x_ss <- nleqslv(st_state_function, x = x_0, method = 'Newton',
control = list(allowSingular = T))
x_ss[["x"]]
# STEP 2:
# Setting the initial guess:
x_0 <- c(0.74, 3.9, 1, 0.07, 0.95)
# STEP 3:
# Solving the function, i.e. finding the steady state numerically:
x_ss <- nleqslv(st_state_function, x = x_0, method = 'Newton',
control = list(allowSingular = T))
View(x_ss)
x_ss[["x"]]
# STEP 3:
# Solving the function, i.e. finding the steady state numerically:
x_ss <- nleqslv(st_state_function, x = x_0, method = 'Newton',
control = list(allowSingular = T))[['x']]
F <- function(x) {a <- matrix(c(1, 3, 2, 4), nrow = 2, ncol = 2, byrow = TRUE)X <- matrix(x,             nrow = 2, ncol = 2, byrow = TRUE)return(c(X %*% X %*% X - a))}x0 <- matrix(1, 2, 2)
F <- function(x) {
a <- matrix(c(1, 3, 2, 4), nrow = 2, ncol = 2, byrow = TRUE)
X <- matrix(x,             nrow = 2, ncol = 2, byrow = TRUE)
return(c(X %*% X %*% X - a))
}
x0 <- matrix(1, 2, 2)
opa <- fsolve(F, x0)
View(opa)
x_ss <- fsolve(st_state_function, x0 = x_0)
# STEP 3:
# Solving the function, i.e. finding the steady state numerically:
x_ss <- nleqslv(st_state_function, x = x_0, method = 'Newton',
control = list(allowSingular = T))[['x']]
# STEP 3:
# Solving the function, i.e. finding the steady state numerically:
x_ss <- nleqslv(st_state_function, x = x_0, method = 'Newton')[['x']]
# STEP 3:
# Solving the function, i.e. finding the steady state numerically:
x_ss <- nleqslv(st_state_function, x = x_0, method = 'Newton')
View(x_ss)
View(x_ss)
View(x_ss)
# STEP 3:
# Solving the function, i.e. finding the steady state numerically:
x_ss <- nleqslv(st_state_function, x = x_0, method = 'Newton',
control = list(cndtol = 10^(-19)))[['x']]
# STEP 3:
# Solving the function, i.e. finding the steady state numerically:
x_ss <- nleqslv(st_state_function, x = x_0, method = 'Newton',
control = list(cndtol = 10^(-19)))
View(x_ss)
x_ss <- nleqslv(st_state_function, x = x_0, method = 'Broyden')
View(x_ss)
View(x_ss)
x_ss[['x']]
z = 2*z # new productivity parameter - doubling the old one
x_ss_2 <- nleqslv(st_state_function, x = x_0, method = 'Newton',
control = list(cndtol = 10^(-19)))
View(x_ss_2)
View(x_ss)
h = 0.31; theta = 0.67; k_to_y = 4; i_to_y = 0.25;
z = 1.629 # as suggested
# STEP 2:
# Setting the initial guess:
x_0 <- c(0.74, 3.9, 1, 0.07, 0.95)
# STEP 3:
# Solving the function, i.e. finding the steady state numerically:
x_ss <- nleqslv(st_state_function, x = x_0, method = 'Newton',
control = list(cndtol = 10^(-19)))
View(x_ss)
z = 2*z # new productivity parameter - doubling the old one
x_ss_2 <- nleqslv(st_state_function, x = x_0, method = 'Newton',
control = list(cndtol = 10^(-19)))
st_state_function <- function(x){
# The Five Constraints:
#   (which will be equated to zero when obtaining the roots/solution)
# - The Capital-Output Ratio:
k_to_y_constr = k_to_y - x[1]/x[3]
# - The Investment-Output Ratio:
i_to_y_constr = i_to_y - x[4]*x[2]/x[3]
# - The Euler Equation:
ee_constr = (1 - x[4] - (1-theta)*((z*h)/x[2])^theta)*x[5] - 1
# - The Budget/Resource Constraint:
b_constr = x[3] - x[1] - x[2]*x[4]
# - Cobb-Douglas Production:
cd_prod_constr = x[3] - x[2]^(1-theta)*((z*h)^(theta))
# For the five variables of: c_ss, k_ss, y_ss, delta, and beta
# - these are five and not six since we can isolate i_ss as i_ss = k_ss*delta
#   in the budget constraint
# - also considering z to be a parameter rather than a variable
#   [following the arguments in the analytical part - it cancels out]
# - having put these variables into a vector x to match the syntax of the fsolve funct:
# x = (c_ss, k_ss, y_ss, delta, beta)
#     x[1]   x[2]  x[3]  x[4]   x[5]
return(c(k_to_y_constr, i_to_y_constr, ee_constr, b_constr, cd_prod_constr))
}
# STEP 3:
# Solving the function, i.e. finding the steady state numerically:
x_ss <- nleqslv(st_state_function, x = x_0, method = 'Newton',
control = list(cndtol = 10^(-19)))
View(x_ss)
# __________________________________________________________________________
# 0. SOME PRELIMINARIES:
# --------------------------------------------------------------------------
# 0.1. Setting the working directory right
# (automatically, as with the current script's location)
fileloc <- dirname(rstudioapi::getSourceEditorContext()$path)
setwd(fileloc)
# Removing the fileloc string
rm(fileloc)
# Setting locale
Sys.setlocale("LC_ALL", "English")
# --------------------------------------------------------------------------
# 0.2. Loading the necessary packages
library(tidyverse)                                       # for handling data
library(data.table)                                      # for handling data
library(rvest)                                           # for scraping data
# --------------------------------------------------------------------------
# 0.3. Clearing the workspace environment
rm(list = ls())
gc()
# __________________________________________________________________________
# 1. LOADING THE DATA FROM THE SAVED FILES DIRECTLY:
load('saved_data_frames.RData')
load('saved_policy_chains_all_states.RData')
source('EmptyDfForState.R')
source('ENDS_EXTENDS_function.R')
source('EELJ_function.R')
test_eelj <- EELJ_function(state_name = 'Alabama', policy_measure = 'StayAtHome')
source('PolicyType.R')
source('EmergDec.R')
data_measures = COVID_measures_df_REVIEWED
View(states_df)
state_name = 'AL'
policy_state_changes <- EELJ_function(data_measures = data_measures,
state_name = state_name,
policy_measure = policy_measure)
data_measures <- COVID_measures_df_REVIEWED
county_data <- counties_df
state_name <- 'Alabama'
policy_measure <- 'SchoolClose'
policy_type_usual_value <- policy_type_function(policy_measure)
View(policy_type_function)
policy_type_usual_value <- policy_type_function(policy_measure)
# __________________________________________________________________________
# 0. SOME PRELIMINARIES:
# --------------------------------------------------------------------------
# 0.1. Setting the working directory right
# (automatically, as with the current script's location)
fileloc <- dirname(rstudioapi::getSourceEditorContext()$path)
setwd(fileloc)
# Removing the fileloc string
rm(fileloc)
# Setting locale
Sys.setlocale("LC_ALL", "English")
# --------------------------------------------------------------------------
# 0.2. Loading the necessary packages
library(tidyverse)                                       # for handling data
library(data.table)                                      # for handling data
library(rvest)                                           # for scraping data
# --------------------------------------------------------------------------
# 0.3. Clearing the workspace environment
rm(list = ls())
gc()
# __________________________________________________________________________
# 1. LOADING THE DATA FROM THE SAVED FILES DIRECTLY:
load('saved_data_frames.RData')
load('saved_policy_chains_all_states.RData')
source('EmptyDfForState.R')
source('ENDS_EXTENDS_function.R')
source('EELJ_function.R')
test_eelj <- EELJ_function(state_name = 'Alabama', policy_measure = 'StayAtHome')
source('PolicyType.R')
source('EmergDec.R')
data_measures <- COVID_measures_df_REVIEWED
county_data <- counties_df
state_name <- 'Alabama'
policy_measure <- 'SchoolClose'
policy_type_usual_value <- policy_type_function(policy_measure)
policy_type <- policy_type_usual_value[1]
usual_value <- policy_type_usual_value[2]
